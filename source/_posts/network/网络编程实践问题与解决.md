---
title: 网络编程实践问题与解决
date: 2017-11-29 21:18:19
categories: [网络相关]
---

<!-- TOC -->

- [1. 应用层缓冲区](#1-应用层缓冲区)
- [2. 应用层定时器](#2-应用层定时器)

<!-- /TOC -->

<a id="markdown-1-应用层缓冲区" name="1-应用层缓冲区"></a>
# 1. 应用层缓冲区

我是在实践ttcp的时候发现的,https://github.com/yqsy/linux_socket_test/tree/master/ttcp

问题是在使用非阻塞I/O时,每次触发read信号,read得到是一片流,流在变成包的这一个过程中,有许多状态,状态满足之后才能交给应用层(例如收到足够的字节,收到终结符号).

我的做法是在判断状态达成之后才使用read函数去收取(不断的用`ioctl`获取内核缓冲区可读字节数),所以导致了性能的缓慢

参考陈硕的书籍7.4章节,发现解决这一的问题的方法是应用层缓冲区.

libevent 自带的缓冲区性能非常差?我测试的有问题吗?

* https://en.wikipedia.org/wiki/Circular_buffer


应用层的缓冲是必需的,每个TCP socket都要有stateful的input buffer 和 output buffer

如何设计并使用缓冲区?如果有10000个并发连接,每个连接一建立就分配各50KB的读写缓冲区的话,将占用1GB内存, 10W就是10GB,100W就是100GB.

muduo buffer的设计是参考了`Netty的ChannelBuffer`和`Libevent1.4.x的evbuffer`

借助于stl vector的capacity特性

```c++
#include <vector>

#include <stdio.h>

int main() {
  std::vector<char> vec;
  printf("%zd %zd\n", vec.size(), vec.capacity()); //  0 0

  vec.resize(1024);
  printf("%zd %zd\n", vec.size(), vec.capacity()); // 1024 1024

  // 以指数级别上涨的
  vec.resize(1300);
  printf("%zd %zd\n", vec.size(), vec.capacity()); // 1300 2048

  return 0;
}
```

<a id="markdown-2-应用层定时器" name="2-应用层定时器"></a>
# 2. 应用层定时器

使用libevent实现ttcp时发现,ctrl+c退出时,client在FIN_WAIT_1状态了,但是并没有发送FIN出去?所以要维护用户层的定时器
